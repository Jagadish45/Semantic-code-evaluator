{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f0365a",
   "metadata": {},
   "source": [
    "### Importing essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0db44763-5edc-4f70-944a-ad841b20d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import clang.cindex\n",
    "import tempfile\n",
    "from sklearn.model_selection import KFold\n",
    "import logging\n",
    "import re\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175afdc6",
   "metadata": {},
   "source": [
    "### Data file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "754e0a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Question</th>\n",
       "      <th>Correct_Code</th>\n",
       "      <th>Code_with_Error</th>\n",
       "      <th>Total_Marks</th>\n",
       "      <th>AST_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Print the factors of a number</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>CursorKind.FUNCTION_DECL printFactors\\n  Curso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Print the factors of a number</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>CursorKind.FUNCTION_DECL printFactors\\n  Curso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Print the factors of a number</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CursorKind.FUNCTION_DECL printFactors\\n  Curso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Print the factors of a number</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\n\\nvoid printFactors(int nu...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>CursorKind.FUNCTION_DECL printFactors\\n  Curso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Print the factors of a number</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\n\\nvoid printFactors(int nu...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CursorKind.FUNCTION_DECL printFactors\\n  Curso...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       Question  \\\n",
       "0           0  Print the factors of a number   \n",
       "1           1  Print the factors of a number   \n",
       "2           2  Print the factors of a number   \n",
       "3           3  Print the factors of a number   \n",
       "4           4  Print the factors of a number   \n",
       "\n",
       "                                        Correct_Code  \\\n",
       "0  #include <stdio.h>\\nvoid printFactors(int numb...   \n",
       "1  #include <stdio.h>\\nvoid printFactors(int numb...   \n",
       "2  #include <stdio.h>\\nvoid printFactors(int numb...   \n",
       "3  #include <stdio.h>\\nvoid printFactors(int numb...   \n",
       "4  #include <stdio.h>\\nvoid printFactors(int numb...   \n",
       "\n",
       "                                     Code_with_Error  Total_Marks  \\\n",
       "0  #include <stdio.h>\\nvoid printFactors(int numb...          7.0   \n",
       "1  #include <stdio.h>\\nvoid printFactors(int numb...          8.0   \n",
       "2  #include <stdio.h>\\nvoid printFactors(int numb...          5.0   \n",
       "3  #include <stdio.h>\\n\\nvoid printFactors(int nu...          7.0   \n",
       "4  #include <stdio.h>\\n\\nvoid printFactors(int nu...          5.0   \n",
       "\n",
       "                                            AST_full  \n",
       "0  CursorKind.FUNCTION_DECL printFactors\\n  Curso...  \n",
       "1  CursorKind.FUNCTION_DECL printFactors\\n  Curso...  \n",
       "2  CursorKind.FUNCTION_DECL printFactors\\n  Curso...  \n",
       "3  CursorKind.FUNCTION_DECL printFactors\\n  Curso...  \n",
       "4  CursorKind.FUNCTION_DECL printFactors\\n  Curso...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading data\n",
    "data = pd.read_csv('Data_Ast.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7789c8bc",
   "metadata": {},
   "source": [
    "### Code to full AST and partial AST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62220727",
   "metadata": {},
   "outputs": [],
   "source": [
    "####IMPLEMENTATION OF C CODE PARSING USING SIMPLE AST\n",
    "\n",
    "import clang.cindex\n",
    "import tempfile\n",
    "\n",
    "def parse_c_code_from_string(c_code):\n",
    "    \n",
    "    # Create a temporary file to store the C code string\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".c\", delete=False) as tmp_file:\n",
    "        tmp_file.write(c_code.encode())  \n",
    "        tmp_file.flush()  \n",
    "        tmp_file_path = tmp_file.name  \n",
    "\n",
    "    index = clang.cindex.Index.create()\n",
    "    translation_unit = index.parse(tmp_file_path)\n",
    "\n",
    "    # Function to recursively build the AST string representation\n",
    "    def build_ast_string(node, indent=0):\n",
    "        if node.kind == clang.cindex.CursorKind.TRANSLATION_UNIT:\n",
    "            ast_str = \"\"\n",
    "            for child in node.get_children():\n",
    "                ast_str += build_ast_string(child, indent) \n",
    "            return ast_str\n",
    "        else:\n",
    "            ast_str = '  ' * indent + f\"{node.kind}\\n\"\n",
    "            for child in node.get_children():\n",
    "                ast_str += build_ast_string(child, indent + 1) \n",
    "            return ast_str\n",
    "\n",
    "    # Build the AST string starting from the root cursor\n",
    "    ast_representation = build_ast_string(translation_unit.cursor)\n",
    "\n",
    "    return ast_representation\n",
    "\n",
    "data['AST_full'] = data['Code_with_Error'].apply(parse_c_code_from_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c247cc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"Data_AST.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f903b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "####IMPLEMENTATION OF C CODE PARSING USING PARTIAL AST\n",
    "\n",
    "import clang.cindex\n",
    "import tempfile\n",
    "\n",
    "def find_parent_manually(root, target_node):\n",
    "        for child in root.get_children():\n",
    "            # Check if the target_node is among the children\n",
    "            if any(grandchild == target_node for grandchild in child.get_children()):\n",
    "                return child\n",
    "            # Recursively search in deeper children\n",
    "            parent = find_parent_manually(child, target_node)\n",
    "            if parent:\n",
    "                return parent\n",
    "        return None\n",
    "\n",
    "def parse_c_code_from_string(c_code):\n",
    "    # Create a temporary file to store the C code string\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".c\", delete=False) as tmp_file:\n",
    "        tmp_file.write(c_code.encode())\n",
    "        tmp_file.flush()\n",
    "        tmp_file_path = tmp_file.name\n",
    "\n",
    "    # Create an index for parsing\n",
    "    index = clang.cindex.Index.create()\n",
    "\n",
    "    # Parse the C code from the temporary file\n",
    "    translation_unit = index.parse(tmp_file_path)\n",
    "\n",
    "    # Function to get original code lines for display\n",
    "    original_lines = c_code.splitlines()\n",
    "\n",
    "    # Function to find siblings using Clang's built-in functionality\n",
    "    def find_next_brother(node):\n",
    "        parent = find_parent_manually(translation_unit.cursor, node)\n",
    "        if not parent:\n",
    "            return None\n",
    "\n",
    "        siblings = list(parent.get_children())  \n",
    "        current_index = siblings.index(node) \n",
    "\n",
    "        # Return the next sibling if it exists\n",
    "        if current_index + 1 < len(siblings):\n",
    "            return siblings[current_index + 1]\n",
    "        else:\n",
    "            return find_next_brother(parent)\n",
    "    \n",
    "     # Function to find if right sibling exist\n",
    "    def right_sibling_exist(node):\n",
    "        parent = find_parent_manually(translation_unit.cursor, node)\n",
    "        if not parent:\n",
    "            return None\n",
    "\n",
    "        siblings = list(parent.get_children())  \n",
    "        current_index = siblings.index(node) \n",
    "\n",
    "        # Return the next sibling if it exists\n",
    "        if current_index + 1 < len(siblings):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    \n",
    "    node_same_line=[]        \n",
    "    # Recursive function to build AST string, printing errors and original lines when needed\n",
    "    def build_ast_string(node, indent=0):\n",
    "        ast_str = ''\n",
    "        # Check diagnostics at the current node\n",
    "        #for d in translation_unit.diagnostics:\n",
    "            #print(f\"Line: {d.location.line}, Column: {d.location.column}, Severity: {d.severity}, Message: {d.spelling}\")\n",
    "        \n",
    "        diagnostics =[]\n",
    "        diagnostics_1=[]\n",
    "        \n",
    "        for d in translation_unit.diagnostics:\n",
    "            if d.location.line == node.location.line and node.location.line not in node_same_line:\n",
    "                diagnostics.append(d)\n",
    "                \n",
    "            elif d.location.line == node.location.line+1:\n",
    "                diagnostics_1.append(d)\n",
    "        \n",
    "\n",
    "        if diagnostics and len(list(node.get_children()))==0 and not right_sibling_exist(node):\n",
    "            # If there's a diagnostic, print the error and the code causing it\n",
    "            ast_str += '  ' * indent + f\"{node.kind} {node.spelling}\\n\"\n",
    "            ast_str += '  ' * indent + f\"{original_lines[node.location.line - 1]}\\n\"\n",
    "            #This list ensures that if the error exist in the same line, the code is printed only once and not for all it's childen\n",
    "            node_same_line.append(node.location.line)\n",
    "        else:\n",
    "            # Continue building the AST normally\n",
    "            ast_str += '  ' * indent + f\"{node.kind} {node.spelling}\\n\"\n",
    "        \n",
    "        # Find the next sibling to check lines between the current node and its sibling\n",
    "        sibling = find_next_brother(node)\n",
    "\n",
    "        # Check and print code lines between the current node and its sibling\n",
    "        if sibling and sibling.location.line - node.location.line > 1:\n",
    "            print(sibling.location.line - node.location.line)\n",
    "            # Print lines that are between the current node and its sibling\n",
    "            for line_num in range(node.location.line, sibling.location.line - 1):\n",
    "                line = original_lines[line_num]\n",
    "                if line.strip() and not all(char in ')}] ' for char in line):\n",
    "                    print(\"in\")\n",
    "                    ast_str += '  ' * indent + f\"{line}\\n\"\n",
    "                    \n",
    "        elif sibling is None and len(original_lines)-node.location.line > 1 and  len(list(node.get_children()))==0:\n",
    "            print(\"in\")\n",
    "            # Print lines that are between the current node and its sibling\n",
    "            for line_num in range(node.location.line, len(original_lines) - 1):\n",
    "                line = original_lines[line_num]\n",
    "                if line.strip() and not all(char in '(){}[] ' for char in line):\n",
    "                    ast_str += '  ' * indent + f\"{line}\\n\"\n",
    "            \n",
    "        # Recursively traverse and build AST for child nodes\n",
    "        for child in node.get_children():\n",
    "            ast_str += build_ast_string(child, indent + 1)\n",
    "            \n",
    "        return ast_str\n",
    "\n",
    "    # Build the AST string starting from the root cursor\n",
    "    ast_representation = build_ast_string(translation_unit.cursor)\n",
    "\n",
    "    return ast_representation \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ec8a64",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9716b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_code(text):\n",
    "        #Preprocesses text by removing blank lines, reducing whitespace, and replacing newlines with spaces.\n",
    "        text = '\\n'.join(line for line in text.split('\\n') if line.strip())  # Remove blank lines\n",
    "        text = re.sub(r'\\s{2,}', ' ', text)  # Replace multiple spaces with one\n",
    "        return text.replace('\\n', ' ')  # Replace newlines with spaces\n",
    "\n",
    "def clean_text_AST(text):\n",
    "    \n",
    "    # Split the input into lines while preserving the structure\n",
    "    text = text.replace('CursorKind.', '')\n",
    "    lines = text.splitlines()\n",
    "    cleaned_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "\n",
    "        leading_spaces = len(line) - len(line.lstrip())\n",
    "        stripped_line = line.lstrip()\n",
    "        \n",
    "        # Replace 'CursorKind.' and process each word\n",
    "        words = stripped_line.split()\n",
    "        cleaned_words = []\n",
    "        \n",
    "       \n",
    "        for word in words:\n",
    "            if '_' in word:\n",
    "                parts = word.split('_')\n",
    "                cleaned_word = parts[0][:3]  # First 3 letters before the '_'\n",
    "                \n",
    "                if len(parts) > 1:\n",
    "                    cleaned_word += parts[1][:3]  # Next 3 letters after the '_'\n",
    "                \n",
    "                if len(parts) > 2:\n",
    "                    cleaned_word += parts[2][:2]  # Take 2 letters after the second '_'\n",
    "                \n",
    "                cleaned_words.append(cleaned_word)\n",
    "            else:\n",
    "                cleaned_words.append(word[:4])  # Take the first 4 letters if no '_'\n",
    "\n",
    "        # Rejoin the cleaned words into a single line\n",
    "        cleaned_line = ' '.join(cleaned_words)\n",
    "\n",
    "        # Reapply the leading spaces (indentation) to the line\n",
    "        cleaned_lines.append(' ' * leading_spaces + cleaned_line)\n",
    "\n",
    "    # Join the cleaned lines back into a single string, preserving newlines\n",
    "    cleaned_text = '\\n'.join(cleaned_lines)\n",
    "    text = re.sub(r'\\s{2,}', ' ', cleaned_text)  # Replace multiple spaces with one\n",
    "    return text.replace('\\n', ' ')\n",
    "\n",
    "data['AST_full_Processed']=data['AST_full'].apply(clean_text_AST)\n",
    "data['Code_with_Error_Processed']=data['Code_with_Error'].apply(clean_text_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4caefe",
   "metadata": {},
   "source": [
    "### CodeT5 embedding class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0539ea-9973-4404-bf64-d4c4a6602859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "class CodeT5Embeddings:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # Use CodeT5 tokenizer and model\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codet5-base\")\n",
    "        self.model = AutoModel.from_pretrained(\"Salesforce/codet5-base\").to(self.device)\n",
    "\n",
    "    def _get_embeddings(self, text):\n",
    "        # General method to get CodeT5 embeddings for any text input.\n",
    "        if not text.strip():  # Check if input text is empty or whitespace\n",
    "            logging.warning(f\"Empty input text provided.\")\n",
    "            return torch.zeros(1, 768).to(self.device)\n",
    "\n",
    "        # Tokenize input\n",
    "        tokens = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            max_length=512\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Check if the tokenizer produced no tokens\n",
    "        if tokens['input_ids'].size(1) == 0:\n",
    "            logging.warning(f\"Warning: No tokens found for text snippet: {text[:50]}...\")\n",
    "            return torch.zeros(1, 768).to(self.device)\n",
    "\n",
    "        # Check if the token length exceeds 512\n",
    "        if tokens['input_ids'].size(1) > 512:\n",
    "            logging.warning(f\"Warning: Token size exceeds 512 for text: {text[:50]}...\")\n",
    "            return torch.zeros(1, 768).to(self.device)\n",
    "\n",
    "        # Pass tokens through the model and extract CLS embedding\n",
    "        outputs = self.model.encoder(**tokens)\n",
    "        # CodeT5 uses a CLS token to represent the input, so we extract it\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        return embeddings \n",
    "    \n",
    "    def process_embeddings_in_batches(self, texts, batch_size=16):\n",
    "\n",
    "        all_embeddings = []\n",
    "\n",
    "        # Divide the list into batches of size `batch_size`\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            # Get embeddings for the current batch\n",
    "            batch_embeddings = self._get_batch_embeddings(batch_texts)\n",
    "            all_embeddings.append(batch_embeddings)\n",
    "\n",
    "        # Combine embeddings from all batches\n",
    "        final_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "\n",
    "        # Clear memory\n",
    "        del all_embeddings, batch_embeddings\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        return final_embeddings\n",
    "\n",
    "\n",
    "    def process(self, code, ast_full):        \n",
    "        # Process and return embeddings for code and AST.\n",
    "        code_embedding = self._get_embeddings(code)\n",
    "        ast_embedding = self._get_embeddings(ast_full)\n",
    "        return code_embedding, ast_embedding\n",
    "\n",
    "\n",
    "class CodeT5Processor:\n",
    "    def __init__(self, dataframe, embedding_model, embedding_save_path=\"embeddings.pt\"):\n",
    "        # Initialize the processor with a DataFrame, embedding model, and optional save path.\n",
    "        self.dataframe = dataframe\n",
    "        self.embedding_model = embedding_model\n",
    "        self.embedding_save_path = embedding_save_path\n",
    "        self.embeddings = None  # To store the embeddings\n",
    "\n",
    "    def compute_embeddings(self):\n",
    "        # Compute embeddings for the 'Code_with_Error_Processed' and 'AST_full_Processed' columns in the DataFrame.\n",
    "        code_embeddings = []\n",
    "        ast_embeddings = []\n",
    "        \n",
    "        for idx, row in self.dataframe.iterrows():\n",
    "            code = row['Code_with_Error_Processed']\n",
    "            ast = row['AST_full_Processed']\n",
    "            \n",
    "            # Check if either tokenized code or AST exceeds the length of 512 tokens\n",
    "            code_tokens = self.embedding_model.tokenizer(code, return_tensors=\"pt\")['input_ids']\n",
    "            ast_tokens = self.embedding_model.tokenizer(ast, return_tensors=\"pt\")['input_ids']\n",
    "            \n",
    "            # Log and skip rows where token size is greater than 512 for either code or AST\n",
    "            if len(code_tokens[0]) > 512 or len(ast_tokens[0]) > 512:\n",
    "                logging.warning(f\"Skipping row {idx} due to token size exceeding 512 for code or AST.\")\n",
    "                continue\n",
    "            \n",
    "            # Process embeddings for code and AST\n",
    "            code_embedding, ast_embedding = self.embedding_model.process(code, ast)\n",
    "            \n",
    "            # Store embeddings for this row\n",
    "            code_embeddings.append(code_embedding.cpu())\n",
    "            ast_embeddings.append(ast_embedding.cpu())\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        # Convert to tensors and store\n",
    "        self.embeddings = {\n",
    "            'code_embeddings': torch.stack(code_embeddings),\n",
    "            'ast_embeddings': torch.stack(ast_embeddings)\n",
    "        }\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def save_embeddings(self):\n",
    "        # Save the computed embeddings to a file.\n",
    "        if self.embeddings is None:\n",
    "            raise ValueError(\"No embeddings found. Please compute embeddings first.\")\n",
    "        \n",
    "        torch.save(self.embeddings, self.embedding_save_path)\n",
    "        print(f\"Embeddings saved to {self.embedding_save_path}\")\n",
    "\n",
    "    def load_embeddings(self):\n",
    "        # Load embeddings from the save file.\n",
    "        self.embeddings = torch.load(self.embedding_save_path)\n",
    "        print(f\"Embeddings loaded from {self.embedding_save_path}\")\n",
    "\n",
    "    def get_embeddings(self):\n",
    "        # Return the stored embeddings.\n",
    "        if self.embeddings is None:\n",
    "            raise ValueError(\"No embeddings found. Please compute or load embeddings first.\")\n",
    "        return self.embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857b8544",
   "metadata": {},
   "source": [
    "### Main class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8267ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Salesforce/codet5-base were not used when initializing T5Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing T5Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Embedding extraction\n",
    "embedding_model = CodeT5Embeddings()\n",
    "processor = CodeT5Processor(data, embedding_model)\n",
    "processor.compute_embeddings()\n",
    "processor.save_embeddings()\n",
    "processor.load_embeddings()\n",
    "embeddings = processor.get_embeddings()\n",
    "\n",
    "print(embeddings['code_embeddings'])\n",
    "print(embeddings['ast_embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992da3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isat-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
