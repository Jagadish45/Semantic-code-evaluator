{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9df830c-7665-4e62-9357-76e8a20c74aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import clang.cindex\n",
    "import tempfile\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd472c34-3b8d-4f24-812c-a29d1737bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data_AST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0405fc2-2505-424d-b2b8-b71068380fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Question</th>\n",
       "      <th>Correct_Code</th>\n",
       "      <th>Code_with_Error</th>\n",
       "      <th>Total_Marks</th>\n",
       "      <th>AST_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Print the factors of a number</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>CursorKind.FUNCTION_DECL printFactors\\n  Curso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Print the factors of a number</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>CursorKind.FUNCTION_DECL printFactors\\n  Curso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Print the factors of a number</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CursorKind.FUNCTION_DECL printFactors\\n  Curso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Print the factors of a number</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\n\\nvoid printFactors(int nu...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>CursorKind.FUNCTION_DECL printFactors\\n  Curso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Print the factors of a number</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\n\\nvoid printFactors(int nu...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CursorKind.FUNCTION_DECL printFactors\\n  Curso...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       Question  \\\n",
       "0           0  Print the factors of a number   \n",
       "1           1  Print the factors of a number   \n",
       "2           2  Print the factors of a number   \n",
       "3           3  Print the factors of a number   \n",
       "4           4  Print the factors of a number   \n",
       "\n",
       "                                        Correct_Code  \\\n",
       "0  #include <stdio.h>\\nvoid printFactors(int numb...   \n",
       "1  #include <stdio.h>\\nvoid printFactors(int numb...   \n",
       "2  #include <stdio.h>\\nvoid printFactors(int numb...   \n",
       "3  #include <stdio.h>\\nvoid printFactors(int numb...   \n",
       "4  #include <stdio.h>\\nvoid printFactors(int numb...   \n",
       "\n",
       "                                     Code_with_Error  Total_Marks  \\\n",
       "0  #include <stdio.h>\\nvoid printFactors(int numb...          7.0   \n",
       "1  #include <stdio.h>\\nvoid printFactors(int numb...          8.0   \n",
       "2  #include <stdio.h>\\nvoid printFactors(int numb...          5.0   \n",
       "3  #include <stdio.h>\\n\\nvoid printFactors(int nu...          7.0   \n",
       "4  #include <stdio.h>\\n\\nvoid printFactors(int nu...          5.0   \n",
       "\n",
       "                                            AST_full  \n",
       "0  CursorKind.FUNCTION_DECL printFactors\\n  Curso...  \n",
       "1  CursorKind.FUNCTION_DECL printFactors\\n  Curso...  \n",
       "2  CursorKind.FUNCTION_DECL printFactors\\n  Curso...  \n",
       "3  CursorKind.FUNCTION_DECL printFactors\\n  Curso...  \n",
       "4  CursorKind.FUNCTION_DECL printFactors\\n  Curso...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9fe3a8e7-7040-452b-8e65-ac206fb1bd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Total_Marks']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8eeb6d62-6e74-4e7a-aed0-be22229cc3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "994"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc18e11b-0b3f-4789-919d-1cae3d7b7cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_embeddings = torch.load('embeddings_code.pt',map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ea3824d-3555-4c8e-b433-d4a252d66e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_embeddings = loaded_embeddings['code_embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2b2992f-f41f-4fc7-bec0-151318d2f205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000, 1, 512, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6db4f43-351e-4e0e-aa5c-af98d2f64e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0041)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_embeddings[0][0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13be79a5-307f-4a69-9dd8-d6b5b3a975e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_embedding = code_embeddings.reshape(-1, 512 * 768)  # Flatten the feature dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b937d31-719b-4267-a066-f6034f87350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(flattened_embedding.cpu().numpy())  # Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38a9c2c5-c88c-4c26-a7a5-c422f57e6912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_rf_regressor_cv(embeddings, targets, n_folds=10, output_dir=\"results\"):\n",
    "    \"\"\"\n",
    "    Runs 10-fold cross-validation using Random Forest Regressor.\n",
    "    Calculates and stores the average MAPE, RMSE, and R² values for both train and test sets.\n",
    "    Saves the average results to a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    - embeddings (torch.Tensor): Input embeddings with shape [1, 1000, 1, 512, 768].\n",
    "    - targets (np.ndarray): Target values with shape [n_samples].\n",
    "    - n_folds (int): Number of folds for cross-validation (default: 10).\n",
    "    - output_dir (str): Directory to save the results CSV files (default: \"results\").\n",
    "    \n",
    "    Returns:\n",
    "    - results (dict): Dictionary containing the average MAPE, RMSE, and R² scores.\n",
    "    - test_predictions (np.ndarray): Array of predictions from the test set for each fold.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "     # Assuming embeddings has shape (1000, 512, 768), i.e., 1000 samples, each with 512 tokens and 768 features.\n",
    "    embeddings = embeddings.squeeze(0)  # Remove the singleton dimension (1, 1000, 512, 768) -> (1000, 512, 768)\n",
    "    \n",
    "    # Select the final token's embedding for each sample (the 512th token)\n",
    "    final_layer_embeddings = embeddings[:, -1, :]  # Shape will be (1000, 768), one embedding for each sample\n",
    "    \n",
    "    # Convert to NumPy\n",
    "    X = final_layer_embeddings.cpu().numpy() if isinstance(final_layer_embeddings, torch.Tensor) else final_layer_embeddings\n",
    "    \n",
    "    print(f\"Final layer embeddings shape: {X.shape}\")\n",
    "    \n",
    "    # Use the target values\n",
    "    y = np.array(targets)\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Initialize Random Forest Regressor\n",
    "    rf = RandomForestRegressor(n_estimators=100, n_jobs=-1)\n",
    "    \n",
    "    # Initialize results storage\n",
    "    train_mape_list = []\n",
    "    test_mape_list = []\n",
    "    train_rmse_list = []\n",
    "    test_rmse_list = []\n",
    "    train_r2_list = []\n",
    "    test_r2_list = []\n",
    "    \n",
    "    # Store test predictions\n",
    "    test_predictions = []\n",
    "    \n",
    "    # Running Cross-Validation\n",
    "    kf = KFold(n_splits=n_folds)  # Set the random_state for reproducibility\n",
    "    \n",
    "    for fold, (train_index, test_index) in tqdm(enumerate(kf.split(X), 1), desc=\"Folds\"):\n",
    "        # Train-test split\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Train the model\n",
    "        rf.fit(X_train, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_train_pred = rf.predict(X_train)\n",
    "        y_test_pred = rf.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_mape = mean_absolute_percentage_error(y_train, y_train_pred)\n",
    "        test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "        \n",
    "        train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)  # RMSE\n",
    "        test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)    # RMSE\n",
    "        \n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "        # Append the metrics for this fold\n",
    "        train_mape_list.append(train_mape)\n",
    "        test_mape_list.append(test_mape)\n",
    "        train_rmse_list.append(train_rmse)\n",
    "        test_rmse_list.append(test_rmse)\n",
    "        train_r2_list.append(train_r2)\n",
    "        test_r2_list.append(test_r2)\n",
    "        \n",
    "        # Store test predictions\n",
    "        test_predictions.append(y_test_pred)\n",
    "    \n",
    "    # Calculate average of the metrics\n",
    "    avg_train_mape = np.mean(train_mape_list)\n",
    "    avg_test_mape = np.mean(test_mape_list)\n",
    "    avg_train_rmse = np.mean(train_rmse_list)\n",
    "    avg_test_rmse = np.mean(test_rmse_list)\n",
    "    avg_train_r2 = np.mean(train_r2_list)\n",
    "    avg_test_r2 = np.mean(test_r2_list)\n",
    "    \n",
    "    # Prepare the results as a DataFrame\n",
    "    output_df = pd.DataFrame({\n",
    "        \"Code\": [\"Using final token's embedding\"],  # Adjust description\n",
    "        \"Regressor\": [\"Random Forest\"],  # Specify the regressor type\n",
    "        \"Train_R²\": [avg_train_r2],\n",
    "        \"Train_RMSE\": [avg_train_rmse],\n",
    "        \"Train_MAPE\": [avg_train_mape],\n",
    "        \"Test_R²\": [avg_test_r2],\n",
    "        \"Test_RMSE\": [avg_test_rmse],\n",
    "        \"Test_MAPE\": [avg_test_mape]\n",
    "    })\n",
    "\n",
    "    # Save the average results to CSV file\n",
    "    output_file = os.path.join(output_dir, \"random_forest_avg_results.csv\")\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "\n",
    "    # Report average results\n",
    "    print(\"10-Fold CV Results (Averages):\")\n",
    "    print(f\"Mean Train MAPE: {avg_train_mape:.4f}\")\n",
    "    print(f\"Mean Test MAPE: {avg_test_mape:.4f}\")\n",
    "    print(f\"Mean Train RMSE: {avg_train_rmse:.4f}\")\n",
    "    print(f\"Mean Test RMSE: {avg_test_rmse:.4f}\")\n",
    "    print(f\"Mean Train R²: {avg_train_r2:.4f}\")\n",
    "    print(f\"Mean Test R²: {avg_test_r2:.4f}\")\n",
    "    \n",
    "    print(f\"Results saved to {output_file}\")\n",
    "    \n",
    "    # Concatenate all test predictions from each fold into a single array\n",
    "    test_predictions = np.concatenate(test_predictions, axis=0)\n",
    "    \n",
    "    return {\n",
    "        \"Train_MAPE\": avg_train_mape,\n",
    "        \"Test_MAPE\": avg_test_mape,\n",
    "        \"Train_RMSE\": avg_train_rmse,\n",
    "        \"Test_RMSE\": avg_test_rmse,\n",
    "        \"Train_R²\": avg_train_r2,\n",
    "        \"Test_R²\": avg_test_r2\n",
    "    }, test_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b988db85-2cef-494b-9232-8119f0f4e325",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final layer embeddings shape: (1000, 512, 768)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. StandardScaler expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m target \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal_Marks\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m results, data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRF_predicted_value_code\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m run_rf_regressor_cv(code_embeddings, target)\n",
      "Cell \u001b[0;32mIn[10], line 45\u001b[0m, in \u001b[0;36mrun_rf_regressor_cv\u001b[0;34m(embeddings, targets, n_folds, output_dir)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Standardize features\u001b[39;00m\n\u001b[1;32m     44\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m---> 45\u001b[0m X \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Initialize Random Forest Regressor\u001b[39;00m\n\u001b[1;32m     48\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1084\u001b[0m             (\n\u001b[1;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1094\u001b[0m         )\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:878\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 878\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:914\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[1;32m    883\u001b[0m \n\u001b[1;32m    884\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    913\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 914\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    915\u001b[0m     X,\n\u001b[1;32m    916\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    917\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[1;32m    918\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    919\u001b[0m     reset\u001b[38;5;241m=\u001b[39mfirst_call,\n\u001b[1;32m    920\u001b[0m )\n\u001b[1;32m    921\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1058\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1056\u001b[0m     )\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m-> 1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1061\u001b[0m     )\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m   1064\u001b[0m     _assert_all_finite(\n\u001b[1;32m   1065\u001b[0m         array,\n\u001b[1;32m   1066\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m   1067\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m   1068\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1069\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. StandardScaler expected <= 2."
     ]
    }
   ],
   "source": [
    "target = data['Total_Marks']\n",
    "results, data['RF_predicted_value_code'] = run_rf_regressor_cv(code_embeddings, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9afbc035-72f5-4cc7-87e0-008ea40618ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train_MAPE': 36741866959964.43,\n",
       " 'Test_MAPE': 148123391744216.06,\n",
       " 'Train_RMSE': 0.7075948504117413,\n",
       " 'Test_RMSE': 2.2847412513157095,\n",
       " 'Train_R²': 0.9029128438531018,\n",
       " 'Test_R²': -0.3280744889999238}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81427046-f507-4f72-bf49-391c9ad8a85c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6afab6cb-81c3-43c6-88d0-d88b84e6520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_square = r2_score(data['Total_Marks'], data['RF_predicted_value_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f5d4481-af11-47c1-9766-c18c43676542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.025877597084763115"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "420d4fdc-bf8a-4d21-bd2d-aeebef9901d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def run_xgb_regressor_cv(embeddings, targets, n_folds=10, random_state=42, output_dir=\"results\"):\n",
    "    \"\"\"\n",
    "    Runs 10-fold cross-validation using XGBoost Regressor.\n",
    "    Calculates and stores the average MAPE, RMSE, and R² values for both train and test sets.\n",
    "    Saves the average results to a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    - embeddings (torch.Tensor): Input embeddings with shape [1, seq_len, 1, feature1, feature2].\n",
    "    - targets (np.ndarray): Target values with shape [n_samples].\n",
    "    - n_folds (int): Number of folds for cross-validation (default: 10).\n",
    "    - random_state (int): Random seed for reproducibility.\n",
    "    - output_dir (str): Directory to save the results CSV files (default: \"results\").\n",
    "    \n",
    "    Returns:\n",
    "    - results (dict): Dictionary containing the average MAPE, RMSE, and R² scores.\n",
    "    - test_predictions (np.ndarray): Array of predictions from the test set for each fold.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Flatten the embeddings\n",
    "    flattened_embeddings = embeddings.reshape(-1, embeddings.shape[-2] * embeddings.shape[-1])\n",
    "    \n",
    "    # Convert to NumPy\n",
    "    X = flattened_embeddings.cpu().numpy() if isinstance(flattened_embeddings, torch.Tensor) else flattened_embeddings\n",
    "    y = np.array(targets)\n",
    "    \n",
    "    # Apply PCA for dimensionality reduction \n",
    "    pca = PCA(n_components=50)\n",
    "    X = pca.fit_transform(X)\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Initialize XGBoost Regressor\n",
    "    xgb_reg = xgb.XGBRegressor(n_estimators=100, random_state=random_state, n_jobs=-1)\n",
    "    \n",
    "    # Initialize results storage\n",
    "    train_mape_list = []\n",
    "    test_mape_list = []\n",
    "    train_rmse_list = []\n",
    "    test_rmse_list = []\n",
    "    train_r2_list = []\n",
    "    test_r2_list = []\n",
    "    \n",
    "    # Store test predictions\n",
    "    test_predictions = []\n",
    "    \n",
    "    # Running Cross-Validation\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)  # Set the random_state for reproducibility\n",
    "    \n",
    "    for fold, (train_index, test_index) in tqdm(enumerate(kf.split(X), 1), desc=\"Folds\"):\n",
    "        # Train-test split\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Train the model\n",
    "        xgb_reg.fit(X_train, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_train_pred = xgb_reg.predict(X_train)\n",
    "        y_test_pred = xgb_reg.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_mape = mean_absolute_percentage_error(y_train, y_train_pred)\n",
    "        test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "        \n",
    "        train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)  # RMSE\n",
    "        test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)    # RMSE\n",
    "        \n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "        # Append the metrics for this fold\n",
    "        train_mape_list.append(train_mape)\n",
    "        test_mape_list.append(test_mape)\n",
    "        train_rmse_list.append(train_rmse)\n",
    "        test_rmse_list.append(test_rmse)\n",
    "        train_r2_list.append(train_r2)\n",
    "        test_r2_list.append(test_r2)\n",
    "        \n",
    "        # Store test predictions\n",
    "        test_predictions.append(y_test_pred)\n",
    "    \n",
    "    # Calculate average of the metrics\n",
    "    avg_train_mape = np.mean(train_mape_list)\n",
    "    avg_test_mape = np.mean(test_mape_list)\n",
    "    avg_train_rmse = np.mean(train_rmse_list)\n",
    "    avg_test_rmse = np.mean(test_rmse_list)\n",
    "    avg_train_r2 = np.mean(train_r2_list)\n",
    "    avg_test_r2 = np.mean(test_r2_list)\n",
    "    \n",
    "    # Prepare the results as a DataFrame\n",
    "    output_df = pd.DataFrame({\n",
    "        \"Code\": [\"Using only AST\"],  # Repeat for the row\n",
    "        \"Regressor\": [\"XGBoost\"],  # Specify the regressor type\n",
    "        \"Train_R²\": [avg_train_r2],\n",
    "        \"Train_RMSE\": [avg_train_rmse],\n",
    "        \"Train_MAPE\": [avg_train_mape],\n",
    "        \"Test_R²\": [avg_test_r2],\n",
    "        \"Test_RMSE\": [avg_test_rmse],\n",
    "        \"Test_MAPE\": [avg_test_mape]\n",
    "    })\n",
    "\n",
    "    # Save the average results to CSV file\n",
    "    output_file = os.path.join(output_dir, \"xgboost_avg_results.csv\")\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "\n",
    "    # Report average results\n",
    "    print(\"10-Fold CV Results (Averages):\")\n",
    "    print(f\"Mean Train MAPE: {avg_train_mape:.4f}\")\n",
    "    print(f\"Mean Test MAPE: {avg_test_mape:.4f}\")\n",
    "    print(f\"Mean Train RMSE: {avg_train_rmse:.4f}\")\n",
    "    print(f\"Mean Test RMSE: {avg_test_rmse:.4f}\")\n",
    "    print(f\"Mean Train R²: {avg_train_r2:.4f}\")\n",
    "    print(f\"Mean Test R²: {avg_test_r2:.4f}\")\n",
    "    \n",
    "    print(f\"Results saved to {output_file}\")\n",
    "    \n",
    "    # Concatenate all test predictions from each fold into a single array\n",
    "    test_predictions = np.concatenate(test_predictions, axis=0)\n",
    "    \n",
    "    return {\n",
    "        \"Train_MAPE\": avg_train_mape,\n",
    "        \"Test_MAPE\": avg_test_mape,\n",
    "        \"Train_RMSE\": avg_train_rmse,\n",
    "        \"Test_RMSE\": avg_test_rmse,\n",
    "        \"Train_R²\": avg_train_r2,\n",
    "        \"Test_R²\": avg_test_r2\n",
    "    }, test_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55cc5dcf-dc5e-4cf8-aec4-9add21b06fec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds: 0it [00:00, ?it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 1it [00:00,  4.64it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 2it [00:00,  5.03it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 3it [00:00,  5.22it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 4it [00:00,  5.28it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 5it [00:00,  5.23it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 6it [00:01,  5.32it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 7it [00:01,  5.33it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 8it [00:01,  5.44it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 9it [00:01,  5.44it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 10it [00:01,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Fold CV Results (Averages):\n",
      "Mean Train MAPE: 1255581581807.1975\n",
      "Mean Test MAPE: 83908050905203.0312\n",
      "Mean Train RMSE: 0.4846\n",
      "Mean Test RMSE: 2.0385\n",
      "Mean Train R²: 0.9544\n",
      "Mean Test R²: 0.1768\n",
      "Results saved to results/xgboost_avg_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "XGBR_results, data['XGBR_predicted_value_code'] = run_xgb_regressor_cv(code_embeddings, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be6e0b24-0bf2-4ce6-85cf-92983e6a43ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def run_knn_regressor_cv(embeddings, targets, n_folds=10, random_state=42, output_dir=\"results\"):\n",
    "    \"\"\"\n",
    "    Runs 10-fold cross-validation using K-Nearest Neighbors Regressor.\n",
    "    Calculates and stores the average MAPE, RMSE, and R² values for both train and test sets.\n",
    "    Saves the average results to a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    - embeddings (torch.Tensor): Input embeddings with shape [1, seq_len, 1, feature1, feature2].\n",
    "    - targets (np.ndarray): Target values with shape [n_samples].\n",
    "    - n_folds (int): Number of folds for cross-validation (default: 10).\n",
    "    - random_state (int): Random seed for reproducibility.\n",
    "    - output_dir (str): Directory to save the results CSV files (default: \"results\").\n",
    "    \n",
    "    Returns:\n",
    "    - results (dict): Dictionary containing the average MAPE, RMSE, and R² scores.\n",
    "    - test_predictions (np.ndarray): Array of predictions from the test set for each fold.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Flatten the embeddings\n",
    "    flattened_embeddings = embeddings.reshape(-1, embeddings.shape[-2] * embeddings.shape[-1])\n",
    "    \n",
    "    # Convert to NumPy\n",
    "    X = flattened_embeddings.cpu().numpy() if isinstance(flattened_embeddings, torch.Tensor) else flattened_embeddings\n",
    "    print(X.shape)\n",
    "    y = np.array(targets)\n",
    "    \n",
    "    # Apply PCA for dimensionality reduction (optional)\n",
    "    pca = PCA(n_components=50)\n",
    "    X = pca.fit_transform(X)\n",
    "    print(X.shape)\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Initialize K-Nearest Neighbors Regressor\n",
    "    knn_reg = KNeighborsRegressor(n_neighbors=5)\n",
    "    \n",
    "    # Initialize results storage\n",
    "    train_mape_list = []\n",
    "    test_mape_list = []\n",
    "    train_rmse_list = []\n",
    "    test_rmse_list = []\n",
    "    train_r2_list = []\n",
    "    test_r2_list = []\n",
    "    \n",
    "    # Store test predictions\n",
    "    test_predictions = []\n",
    "    \n",
    "    # Running Cross-Validation\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    for fold, (train_index, test_index) in tqdm(enumerate(kf.split(X), 1), desc=\"Folds\"):\n",
    "        # Train-test split\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Train the model\n",
    "        knn_reg.fit(X_train, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_train_pred = knn_reg.predict(X_train)\n",
    "        y_test_pred = knn_reg.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_mape = mean_absolute_percentage_error(y_train, y_train_pred)\n",
    "        test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "        \n",
    "        train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)  # RMSE\n",
    "        test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)    # RMSE\n",
    "        \n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "        # Append the metrics for this fold\n",
    "        train_mape_list.append(train_mape)\n",
    "        test_mape_list.append(test_mape)\n",
    "        train_rmse_list.append(train_rmse)\n",
    "        test_rmse_list.append(test_rmse)\n",
    "        train_r2_list.append(train_r2)\n",
    "        test_r2_list.append(test_r2)\n",
    "        \n",
    "        # Store test predictions\n",
    "        test_predictions.append(y_test_pred)\n",
    "    \n",
    "    # Calculate average of the metrics\n",
    "    avg_train_mape = np.mean(train_mape_list)\n",
    "    avg_test_mape = np.mean(test_mape_list)\n",
    "    avg_train_rmse = np.mean(train_rmse_list)\n",
    "    avg_test_rmse = np.mean(test_rmse_list)\n",
    "    avg_train_r2 = np.mean(train_r2_list)\n",
    "    avg_test_r2 = np.mean(test_r2_list)\n",
    "    \n",
    "    # Prepare the results as a DataFrame\n",
    "    output_df = pd.DataFrame({\n",
    "        \"Code\": [\"Using only AST\"],\n",
    "        \"Regressor\": [\"KNN\"],\n",
    "        \"Train_R²\": [avg_train_r2],\n",
    "        \"Train_RMSE\": [avg_train_rmse],\n",
    "        \"Train_MAPE\": [avg_train_mape],\n",
    "        \"Test_R²\": [avg_test_r2],\n",
    "        \"Test_RMSE\": [avg_test_rmse],\n",
    "        \"Test_MAPE\": [avg_test_mape]\n",
    "    })\n",
    "\n",
    "    # Save the average results to CSV file\n",
    "    output_file = os.path.join(output_dir, \"knn_avg_results.csv\")\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "\n",
    "    # Report average results\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "    \n",
    "    \n",
    "    # Concatenate all test predictions from each fold into a single array\n",
    "    test_predictions = np.concatenate(test_predictions, axis=0)\n",
    "    \n",
    "    return {\n",
    "        \"Train_MAPE\": avg_train_mape,\n",
    "        \"Test_MAPE\": avg_test_mape,\n",
    "        \"Train_RMSE\": avg_train_rmse,\n",
    "        \"Test_RMSE\": avg_test_rmse,\n",
    "        \"Train_R²\": avg_train_r2,\n",
    "        \"Test_R²\": avg_test_r2\n",
    "    }, test_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2401f2a2-4368-4f09-b769-c5a682a8f51d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds: 0it [00:00, ?it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 1it [00:00,  4.43it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 3it [00:00,  9.02it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 7it [00:00, 18.70it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 10it [00:00, 19.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results/knn_avg_results.csv\n"
     ]
    }
   ],
   "source": [
    "KNN_results, data['KNN_predicted_value_code'] = run_knn_regressor_cv(code_embeddings, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f435ba32-6a70-40d5-8c77-1dbb7c4f4e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def run_catboost_regressor_cv(embeddings, targets, n_folds=10, random_state=42, output_dir=\"results\"):\n",
    "    \"\"\"\n",
    "    Runs 10-fold cross-validation using CatBoost Regressor.\n",
    "    Calculates and stores the average MAPE, RMSE, and R² values for both train and test sets.\n",
    "    Saves the average results to a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    - embeddings (torch.Tensor): Input embeddings with shape [1, seq_len, 1, feature1, feature2].\n",
    "    - targets (np.ndarray): Target values with shape [n_samples].\n",
    "    - n_folds (int): Number of folds for cross-validation (default: 10).\n",
    "    - random_state (int): Random seed for reproducibility.\n",
    "    - output_dir (str): Directory to save the results CSV files (default: \"results\").\n",
    "    \n",
    "    Returns:\n",
    "    - results (dict): Dictionary containing the average MAPE, RMSE, and R² scores.\n",
    "    - test_predictions (np.ndarray): Array of predictions from the test set for each fold.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Flatten the embeddings\n",
    "    flattened_embeddings = embeddings.reshape(-1, embeddings.shape[-2] * embeddings.shape[-1])\n",
    "    \n",
    "    # Convert to NumPy\n",
    "    X = flattened_embeddings.cpu().numpy() if isinstance(flattened_embeddings, torch.Tensor) else flattened_embeddings\n",
    "    y = np.array(targets)\n",
    "    \n",
    "    # Apply PCA for dimensionality reduction (optional)\n",
    "    pca = PCA(n_components=50)\n",
    "    X = pca.fit_transform(X)\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Initialize CatBoost Regressor\n",
    "    catboost_reg = CatBoostRegressor(iterations=100, random_state=random_state, silent=True)\n",
    "    \n",
    "    # Initialize results storage\n",
    "    train_mape_list = []\n",
    "    test_mape_list = []\n",
    "    train_rmse_list = []\n",
    "    test_rmse_list = []\n",
    "    train_r2_list = []\n",
    "    test_r2_list = []\n",
    "    \n",
    "    # Store test predictions\n",
    "    test_predictions = []\n",
    "    \n",
    "    # Running Cross-Validation\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    for fold, (train_index, test_index) in tqdm(enumerate(kf.split(X), 1), desc=\"Folds\"):\n",
    "        # Train-test split\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Train the model\n",
    "        catboost_reg.fit(X_train, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_train_pred = catboost_reg.predict(X_train)\n",
    "        y_test_pred = catboost_reg.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_mape = mean_absolute_percentage_error(y_train, y_train_pred)\n",
    "        test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "        \n",
    "        train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)  # RMSE\n",
    "        test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)    # RMSE\n",
    "        \n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "        # Append the metrics for this fold\n",
    "        train_mape_list.append(train_mape)\n",
    "        test_mape_list.append(test_mape)\n",
    "        train_rmse_list.append(train_rmse)\n",
    "        test_rmse_list.append(test_rmse)\n",
    "        train_r2_list.append(train_r2)\n",
    "        test_r2_list.append(test_r2)\n",
    "        \n",
    "        # Store test predictions\n",
    "        test_predictions.append(y_test_pred)\n",
    "    \n",
    "    # Calculate average of the metrics\n",
    "    avg_train_mape = np.mean(train_mape_list)\n",
    "    avg_test_mape = np.mean(test_mape_list)\n",
    "    avg_train_rmse = np.mean(train_rmse_list)\n",
    "    avg_test_rmse = np.mean(test_rmse_list)\n",
    "    avg_train_r2 = np.mean(train_r2_list)\n",
    "    avg_test_r2 = np.mean(test_r2_list)\n",
    "    \n",
    "    # Prepare the results as a DataFrame\n",
    "    output_df = pd.DataFrame({\n",
    "        \"Code\": [\"Using only AST\"],\n",
    "        \"Regressor\": [\"CatBoost\"],\n",
    "        \"Train_R²\": [avg_train_r2],\n",
    "        \"Train_RMSE\": [avg_train_rmse],\n",
    "        \"Train_MAPE\": [avg_train_mape],\n",
    "        \"Test_R²\": [avg_test_r2],\n",
    "        \"Test_RMSE\": [avg_test_rmse],\n",
    "        \"Test_MAPE\": [avg_test_mape]\n",
    "    })\n",
    "\n",
    "    # Save the average results to CSV file\n",
    "    output_file = os.path.join(output_dir, \"catboost_avg_results.csv\")\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "\n",
    "    # Report average results\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "    \n",
    "    # Concatenate all test predictions from each fold into a single array\n",
    "    test_predictions = np.concatenate(test_predictions, axis=0)\n",
    "    \n",
    "    return {\n",
    "        \"Train_MAPE\": avg_train_mape,\n",
    "        \"Test_MAPE\": avg_test_mape,\n",
    "        \"Train_RMSE\": avg_train_rmse,\n",
    "        \"Test_RMSE\": avg_test_rmse,\n",
    "        \"Train_R²\": avg_train_r2,\n",
    "        \"Test_R²\": avg_test_r2\n",
    "    }, test_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9cc07f7c-9049-4c7d-9b59-a1b8070e13b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds: 0it [00:00, ?it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 1it [00:00,  4.04it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 2it [00:00,  4.82it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 3it [00:00,  5.10it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 4it [00:00,  5.25it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 5it [00:00,  5.29it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 6it [00:01,  5.25it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 7it [00:01,  5.23it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 8it [00:01,  5.33it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 9it [00:01,  4.87it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 10it [00:01,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results/catboost_avg_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CATBoost_results, data['CATBoost_predicted_value_code'] = run_catboost_regressor_cv(code_embeddings, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "743640aa-f88e-44c3-9228-71cbae8e86f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def run_svr_regressor_cv(embeddings, targets, n_folds=10, random_state=42, output_dir=\"results\"):\n",
    "    \"\"\"\n",
    "    Runs 10-fold cross-validation using Support Vector Regressor.\n",
    "    Calculates and stores the average MAPE, RMSE, and R² values for both train and test sets.\n",
    "    Saves the average results to a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    - embeddings (torch.Tensor): Input embeddings with shape [1, seq_len, 1, feature1, feature2].\n",
    "    - targets (np.ndarray): Target values with shape [n_samples].\n",
    "    - n_folds (int): Number of folds for cross-validation (default: 10).\n",
    "    - random_state (int): Random seed for reproducibility.\n",
    "    - output_dir (str): Directory to save the results CSV files (default: \"results\").\n",
    "    \n",
    "    Returns:\n",
    "    - results (dict): Dictionary containing the average MAPE, RMSE, and R² scores.\n",
    "    - test_predictions (np.ndarray): Array of predictions from the test set for each fold.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Flatten the embeddings\n",
    "    flattened_embeddings = embeddings.reshape(-1, embeddings.shape[-2] * embeddings.shape[-1])\n",
    "    \n",
    "    # Convert to NumPy\n",
    "    X = flattened_embeddings.cpu().numpy() if isinstance(flattened_embeddings, torch.Tensor) else flattened_embeddings\n",
    "    y = np.array(targets)\n",
    "    \n",
    "    # Apply PCA for dimensionality reduction (optional)\n",
    "    pca = PCA(n_components=50)\n",
    "    X = pca.fit_transform(X)\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Initialize Support Vector Regressor\n",
    "    svr_reg = SVR(kernel='rbf')\n",
    "    \n",
    "    # Initialize results storage\n",
    "    train_mape_list = []\n",
    "    test_mape_list = []\n",
    "    train_rmse_list = []\n",
    "    test_rmse_list = []\n",
    "    train_r2_list = []\n",
    "    test_r2_list = []\n",
    "    \n",
    "    # Store test predictions\n",
    "    test_predictions = []\n",
    "    \n",
    "    # Running Cross-Validation\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    for fold, (train_index, test_index) in tqdm(enumerate(kf.split(X), 1), desc=\"Folds\"):\n",
    "        # Train-test split\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Train the model\n",
    "        svr_reg.fit(X_train, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_train_pred = svr_reg.predict(X_train)\n",
    "        y_test_pred = svr_reg.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_mape = mean_absolute_percentage_error(y_train, y_train_pred)\n",
    "        test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "        \n",
    "        train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)  # RMSE\n",
    "        test_rmse = mean_squared_error(y_test, y_test_pred, squared=False)    # RMSE\n",
    "        \n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "        # Append the metrics for this fold\n",
    "        train_mape_list.append(train_mape)\n",
    "        test_mape_list.append(test_mape)\n",
    "        train_rmse_list.append(train_rmse)\n",
    "        test_rmse_list.append(test_rmse)\n",
    "        train_r2_list.append(train_r2)\n",
    "        test_r2_list.append(test_r2)\n",
    "        \n",
    "        # Store test predictions\n",
    "        test_predictions.append(y_test_pred)\n",
    "    \n",
    "    # Calculate average of the metrics\n",
    "    avg_train_mape = np.mean(train_mape_list)\n",
    "    avg_test_mape = np.mean(test_mape_list)\n",
    "    avg_train_rmse = np.mean(train_rmse_list)\n",
    "    avg_test_rmse = np.mean(test_rmse_list)\n",
    "    avg_train_r2 = np.mean(train_r2_list)\n",
    "    avg_test_r2 = np.mean(test_r2_list)\n",
    "    \n",
    "    # Prepare the results as a DataFrame\n",
    "    output_df = pd.DataFrame({\n",
    "        \"Code\": [\"Using only AST\"],\n",
    "        \"Regressor\": [\"SVR\"],\n",
    "        \"Train_R²\": [avg_train_r2],\n",
    "        \"Train_RMSE\": [avg_train_rmse],\n",
    "        \"Train_MAPE\": [avg_train_mape],\n",
    "        \"Test_R²\": [avg_test_r2],\n",
    "        \"Test_RMSE\": [avg_test_rmse],\n",
    "        \"Test_MAPE\": [avg_test_mape]\n",
    "    })\n",
    "\n",
    "    # Save the average results to CSV file\n",
    "    output_file = os.path.join(output_dir, \"svr_avg_results.csv\")\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "\n",
    "    # Report average results\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "    \n",
    "    # Concatenate all test predictions from each fold into a single array\n",
    "    test_predictions = np.concatenate(test_predictions, axis=0)\n",
    "    \n",
    "    return {\n",
    "        \"Train_MAPE\": avg_train_mape,\n",
    "        \"Test_MAPE\": avg_test_mape,\n",
    "        \"Train_RMSE\": avg_train_rmse,\n",
    "        \"Test_RMSE\": avg_test_rmse,\n",
    "        \"Train_R²\": avg_train_r2,\n",
    "        \"Test_R²\": avg_test_r2\n",
    "    }, test_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "906e7f36-3227-472f-84fd-65848f2a5416",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds: 0it [00:00, ?it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 1it [00:00,  6.03it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 2it [00:00,  6.17it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 3it [00:00,  6.28it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 4it [00:00,  6.34it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 5it [00:00,  6.37it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 6it [00:00,  6.40it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 7it [00:01,  6.41it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 8it [00:01,  6.42it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 9it [00:01,  6.38it/s]/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/jagadeeshgurram/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "Folds: 10it [00:01,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results/svr_avg_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "SVR_results, data['SVR_predicted_value_code'] = run_svr_regressor_cv(code_embeddings, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b16eeda4-b54e-471b-bc0e-eb8692b8aaec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Question</th>\n",
       "      <th>Correct_Code</th>\n",
       "      <th>Code_with_Error</th>\n",
       "      <th>Total_Marks</th>\n",
       "      <th>AST_full</th>\n",
       "      <th>RF_predicted_value_code</th>\n",
       "      <th>XGBR_predicted_value_code</th>\n",
       "      <th>KNN_predicted_value_code</th>\n",
       "      <th>CATBoost_predicted_value_code</th>\n",
       "      <th>SVR_predicted_value_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Print the factors of a number</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>CursorKind.FUNCTION_DECL printFactors\\n  Curso...</td>\n",
       "      <td>5.350000</td>\n",
       "      <td>4.256089</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.603391</td>\n",
       "      <td>5.457184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Print the factors of a number</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>CursorKind.FUNCTION_DECL printFactors\\n  Curso...</td>\n",
       "      <td>5.358000</td>\n",
       "      <td>4.664847</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.306713</td>\n",
       "      <td>5.305394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Print the factors of a number</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CursorKind.FUNCTION_DECL printFactors\\n  Curso...</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>5.801123</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.549781</td>\n",
       "      <td>5.265496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Print the factors of a number</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\n\\nvoid printFactors(int nu...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>CursorKind.FUNCTION_DECL printFactors\\n  Curso...</td>\n",
       "      <td>5.144783</td>\n",
       "      <td>5.269772</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.409132</td>\n",
       "      <td>5.826906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Print the factors of a number</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\n\\nvoid printFactors(int nu...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CursorKind.FUNCTION_DECL printFactors\\n  Curso...</td>\n",
       "      <td>6.040000</td>\n",
       "      <td>7.046596</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.455247</td>\n",
       "      <td>5.928104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       Question  \\\n",
       "0           0  Print the factors of a number   \n",
       "1           1  Print the factors of a number   \n",
       "2           2  Print the factors of a number   \n",
       "3           3  Print the factors of a number   \n",
       "4           4  Print the factors of a number   \n",
       "\n",
       "                                        Correct_Code  \\\n",
       "0  #include <stdio.h>\\nvoid printFactors(int numb...   \n",
       "1  #include <stdio.h>\\nvoid printFactors(int numb...   \n",
       "2  #include <stdio.h>\\nvoid printFactors(int numb...   \n",
       "3  #include <stdio.h>\\nvoid printFactors(int numb...   \n",
       "4  #include <stdio.h>\\nvoid printFactors(int numb...   \n",
       "\n",
       "                                     Code_with_Error  Total_Marks  \\\n",
       "0  #include <stdio.h>\\nvoid printFactors(int numb...          7.0   \n",
       "1  #include <stdio.h>\\nvoid printFactors(int numb...          8.0   \n",
       "2  #include <stdio.h>\\nvoid printFactors(int numb...          5.0   \n",
       "3  #include <stdio.h>\\n\\nvoid printFactors(int nu...          7.0   \n",
       "4  #include <stdio.h>\\n\\nvoid printFactors(int nu...          5.0   \n",
       "\n",
       "                                            AST_full  RF_predicted_value_code  \\\n",
       "0  CursorKind.FUNCTION_DECL printFactors\\n  Curso...                 5.350000   \n",
       "1  CursorKind.FUNCTION_DECL printFactors\\n  Curso...                 5.358000   \n",
       "2  CursorKind.FUNCTION_DECL printFactors\\n  Curso...                 5.440000   \n",
       "3  CursorKind.FUNCTION_DECL printFactors\\n  Curso...                 5.144783   \n",
       "4  CursorKind.FUNCTION_DECL printFactors\\n  Curso...                 6.040000   \n",
       "\n",
       "   XGBR_predicted_value_code  KNN_predicted_value_code  \\\n",
       "0                   4.256089                       5.2   \n",
       "1                   4.664847                       5.4   \n",
       "2                   5.801123                       4.8   \n",
       "3                   5.269772                       4.4   \n",
       "4                   7.046596                       6.4   \n",
       "\n",
       "   CATBoost_predicted_value_code  SVR_predicted_value_code  \n",
       "0                       5.603391                  5.457184  \n",
       "1                       5.306713                  5.305394  \n",
       "2                       4.549781                  5.265496  \n",
       "3                       4.409132                  5.826906  \n",
       "4                       6.455247                  5.928104  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "00a1d788-3301-486a-b544-66cfd4144b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Total_Marks']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b577d276-082b-42b9-babb-e58bdf376e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Regressor        R²      RMSE       MAPE\n",
      "RF              RF -0.508959  2.737975  55.325608\n",
      "XGBR          XGBR -0.719550  2.922794  57.933209\n",
      "KNN            KNN -0.676626  2.886083  57.522456\n",
      "CATBoost  CATBoost -0.601788  2.820936  56.655027\n",
      "SVR            SVR -0.299060  2.540420  52.106045\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define a function to calculate the evaluation metrics\n",
    "def calculate_metrics(true_values, predicted_values):\n",
    "    # R²\n",
    "    r2 = 1 - (np.sum((true_values - predicted_values) ** 2) / np.sum((true_values - np.mean(true_values)) ** 2))\n",
    "    \n",
    "    # RMSE\n",
    "    rmse = np.sqrt(np.mean((true_values - predicted_values) ** 2))\n",
    "    \n",
    "    # MAPE\n",
    "    mape = np.mean(np.abs((true_values - predicted_values) / true_values)) * 100\n",
    "    \n",
    "    return r2, rmse, mape\n",
    "\n",
    "# Assuming 'df' contains the true values and predictions\n",
    "true_values = data[\"Total_Marks\"].values\n",
    "\n",
    "# Calculate metrics for each regressor\n",
    "metrics = {}\n",
    "for model in ['RF', 'XGBR', 'KNN', 'CATBoost', 'SVR']:\n",
    "    predicted_values = data[f\"{model}_predicted_value_code\"].values\n",
    "    r2, rmse, mape = calculate_metrics(true_values, predicted_values)\n",
    "    metrics[model] = {\"r_squared\": r2, \"rmse\": rmse, \"mape\": mape}\n",
    "\n",
    "# Create a DataFrame to store results in the desired format\n",
    "result_df = pd.DataFrame(metrics).T\n",
    "\n",
    "# Now adjust the format so that regressor names are in the first column\n",
    "final_df = result_df[['r_squared', 'rmse', 'mape']].rename(columns={\n",
    "    'r_squared': 'R²',\n",
    "    'rmse': 'RMSE',\n",
    "    'mape': 'MAPE'\n",
    "})\n",
    "\n",
    "# Display the final DataFrame\n",
    "final_df['Regressor'] = final_df.index\n",
    "final_df = final_df[['Regressor', 'R²', 'RMSE', 'MAPE']]\n",
    "\n",
    "# Saving the result to CSV or display\n",
    "final_df.to_csv(\"regressor_metrics.csv\", index=False)\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc89baa-8ad2-4353-8433-4eb12139a0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "# Define the BiLSTM model\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 1)  # *2 for bidirectional\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, input_dim)\n",
    "        lstm_out, _ = self.lstm(x)  # lstm_out: (batch_size, seq_len, hidden_dim * 2)\n",
    "        out = self.fc(lstm_out)  # out: (batch_size, seq_len, 1)\n",
    "        return out\n",
    "\n",
    "# Dataset class for the embeddings and targets\n",
    "class CodeDataset(Dataset):\n",
    "    def __init__(self, embeddings, targets):\n",
    "        self.embeddings = embeddings\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.targets[idx]\n",
    "\n",
    "\n",
    "def train_bilstm(embeddings, targets, input_dim, hidden_dim, num_layers, num_epochs, batch_size, device):\n",
    "    dataset = CodeDataset(embeddings, targets)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = BiLSTM(input_dim, hidden_dim, num_layers).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch_embeddings, batch_targets in dataloader:\n",
    "            batch_embeddings = batch_embeddings.to(device)\n",
    "            batch_targets = batch_targets.to(device).view(-1, 1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            batch_embeddings = batch_embeddings.view(batch_embeddings.size(0), -1, input_dim)\n",
    "            outputs = model(batch_embeddings)  # [batch_size, seq_len, hidden_dim*2]\n",
    "            embeddings_out = outputs.mean(dim=1)  # [batch_size, hidden_dim*2]\n",
    "\n",
    "            loss = criterion(embeddings_out, batch_targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(dataloader)}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Main processing script\n",
    "if __name__ == \"__main__\":\n",
    "    # Assume code_embeddings has shape (num_samples, seq_len, embedding_dim)\n",
    "    embeddings = loaded_embeddings['code_embeddings']\n",
    "    total_marks = data['Total_Marks'].values\n",
    "\n",
    "    # # Ensure embeddings and targets have the same length\n",
    "    # assert len(embeddings) == len(total_marks), \"Embeddings and targets must have the same length.\"\n",
    "\n",
    "    # Process the embeddings through BiLSTM\n",
    "    processed_model = train_bilstm(\n",
    "        embeddings=embeddings,\n",
    "        targets=total_marks,\n",
    "        input_dim=embeddings.shape[-1],  # embedding_dim\n",
    "        hidden_dim=128,\n",
    "        num_layers=2,\n",
    "        num_epochs=10,\n",
    "        batch_size=32,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    "\n",
    "    # Optionally save the model or processed embeddings\n",
    "    torch.save(processed_model.state_dict(), \"bilstm_model.pth\")\n",
    "    print(\"Model saved to 'bilstm_model.pth'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ee9601d8-8733-430f-9cfc-c9cc746be45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data_with_regression_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a04c70d5-e6ec-4e6c-8c10-4895a085d550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened embeddings length: 512000\n",
      "Total marks length: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Flattened embeddings length: {len(flattened_embeddings)}\")\n",
    "print(f\"Total marks length: {len(total_marks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e5a323f0-b87b-4c77-b5b4-da033f2f5029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000, 1, 512, 768)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c1fd02b9-b21c-4cc5-8269-e232e17f3401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened embeddings shape: torch.Size([1000, 512, 768])\n"
     ]
    }
   ],
   "source": [
    "embeddings = embeddings.squeeze()  # This will remove all dimensions with size 1, making it (1000, 512, 768)\n",
    "print(f\"Flattened embeddings shape: {embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1075099-c796-4fb3-bc87-6460281cc886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
